---
layout:     post
title:      "周末学习"
subtitle:   "2019/03/02 广义线性模型"
date:       2019-03-02
author:     "WangXiaoDong"
header-img: "https://github.com/Dongzhixiao/PictureCache/blob/master/diaryPic/20190302.jpg?raw=true"
tags:
    - 日记
    - 广义线性模型
---


```
    周六，我仔细思考了一下最近研究的广义线性模型，感觉这个模型太厉害了。
```


吴恩达老师讲义第一章就是介绍广义线性模型的，我仔细研读该文档$$10$$遍以上，了解
了这篇文档主要讲的就是：**如何写出一个给定$$x$$下$$y$$概率密度函数属于指数簇的这一类学习算法
的假设函数，并如何根据最大似然估计原理以及梯度下降算法进行计算估计得到模型的概率密度
函数的参数的问题。**

首先明确下广义线性模型在机器学习中占据的位置。显然，其属于：

- 有监督学习(其他还有无监督学习、半监督学习以及自监督学习)；
- 判别式算法(其他还有生成式算法)；
- 在概率中属于参数统计(其他还有非参数统计)。

而所以广义线性模型非常有意思，是因为其包含了很多学习算法：

- 正态分布，就是常见的假设函数的外层函数还是正态分布的一类学习算法
- 二项分布，就是常见的假设函数的外层函数是逻辑回归函数的一类学习算法
- 例如多项式分布（multinomial），就是常见的假设函数的外层函数是softmax函数的一类学习算法
- 泊松分布（Poisson）
- 伽马和指数分布（the gamma and the exponential），这个用于对连续的、非负的随机变量进行建模，例如时间间隔；
- 贝塔和狄利克雷分布（the beta and the Dirichlet），这个是用于概率的分布；
- 还有很多，这里就不一一列举了。

其中广义线性模型最重要的就是三个假设：

1. $$y\vert x;\theta ∼ Exponential Family(\eta)$$，即给定 $$x$$ 和 $$\theta, y$$ 的分布属于指数分布族，是一个参数为 $$\eta$$ 的指数分布。——**假设1**

2.	给定 $$x$$，目的是要预测对应这个给定 $$x$$ 的 $$T(y)$$ 的期望值。咱们的例子中绝大部分情况都是 $$T(y) = y$$，这也就意味着我们的学习假设 $$h$$ 输出的预测值 $$h(x)$$ 要满足 $$h(x) = E[y\vert x]$$。 （注意，这个假设通过对 $$h_\theta(x)$$ 的选择而满足，在逻辑回归和线性回归中都是如此。例如在逻辑回归中， $$h_\theta (x) = [p (y = 1\vert x; \theta)] =[ 0 \cdot p (y = 0\vert x; \theta)+1\cdot p(y = 1\vert x;\theta)] = E[y\vert x;\theta]$$。**译者注：这里的$$E[y\vert x]$$应该就是对给定$x$时的$y$值的期望的意思。**）——**假设2**

3.	自然参数 $$\eta$$ 和输入值 $$x$$ 是线性相关的，$$\eta = \theta^T x$$，或者如果 $$\eta$$ 是有值的向量，则有$$\eta_i = \theta_i^T x$$。——**假设3**

可见，第一个假设给出了广义线性模型的使用场景，第二个假设给出了广义线性模型假设函数的构造方法，第三个假设给出了广义线性模型必定包含$$\theta^T x$$这一项，也就说明了广义线性模型之所以有“线性”这个词的原因~