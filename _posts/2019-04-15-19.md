---
layout:     post
title:      "继续学习pytorch"
subtitle:   "2019/04/15 从新整理代码"
date:       2019-04-15
author:     "WangXiaoDong"
header-img: "https://github.com/Dongzhixiao/PictureCache/blob/master/diaryPic/20190415.jpg?raw=true"
tags:
    - 日记
    - Pytorch
---


```
    最近，使用pytorch重新实现神经网络。
```

- 15号，实现数据预处理
- 16号，实现模型建立
- 17号，实现批处理，顺便向孙师兄学习相关知识，如下：
    - 1. `h_state = h_state.data # 重置隐藏层的状态, 切断和前一次迭代的链接`的含义：
    一个是张量，一个是里面的数据，数据只是数据本身，不依赖于其它张量，和其它张量没有关系，可以理解成深拷贝
    - 2. h = net.init_hidden(batch_size)# 初始化隐状态的方案，两种：
        - 所有样本数据之间有时间上关联性，则每个epoch开始时初始化一次；
        - 所有样本数据之间无时间上关联性，则每个小批开始是初始化一次。    
- 18号，完善代码
- 19号，测试代码